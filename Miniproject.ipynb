{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject 1: Storage capacity in biologically plausible Hopfield networks #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hopfield model is a standard model in computational neuroscience that models the storage of memory items, in the form of “patterns” of neuronal activity, in the recurrent connectivity of a neural network.\n",
    "\n",
    "The aim of this project is to investigate the robustness of memory retrieval in Hopfield networks with biologically plausible constraints. The lectures mostly covered standard Hopfield networks with balanced patterns and a symmetric weight matrix.\n",
    "\n",
    "However, in biological networks, neural activity is generally sparse with only a few neurons active at a time.\n",
    "\n",
    "Moreover, the symmetric connectivity of the standard Hopfield model is inconsistent with Dale’s law which states that the outgoing synapses from each neuron should be either excitatory or inhibitory; and it is very unlikely to find symmetric connectivity in the brain.\n",
    "\n",
    "To address these issues, we will generalise the Hopfield model to low-activity patterns and separated excitatory and inhibitory populations. We will first start with a classic symmetric Hopfield network, and investigate the capacity of this network in storing balanced random patterns, i.e. with 50% of active neurons in the network.\n",
    "\n",
    "In the second part, we will simulate a network with low-activity patterns. Finally, in the third section, we will separate the network into excitatory and inhibitory populations, and explore memory retrieval.\n",
    "\n",
    "Note: the project is intended to be solved using Python without the need for any specific library (other than the usual numpy and matplotlib). You are free to use other libraries if you want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 0. Getting Started: Standard Hopfield Network ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we first consider the classical Hopfield model with balanced random patterns, consisting of $N$ fully connected, continuously-valued nodes $S_i(t) \\in [−1,\\, 1]$. The $M$ memory patterns $P^{\\mu} \\in \\{−1, 1\\}^{N}$ where each component is either +1 or −1 with probability $\\frac{1}{2}$, are stored in the network by the weight matrix given in the standard Hebbian form.\n",
    "\n",
    "$$\n",
    "W_{ij} = \\frac{1}{N} \\sum_{\\mu = 1}^M P^{\\mu}_i P^{\\mu}_j\n",
    "$$\n",
    "\n",
    "At each time step, the states update according to the rule:\n",
    "\n",
    "$$\n",
    "S_i(t + 1) = \\phi \\Biggl( \\sum_{j = 1}^N W_{ij} S_j(t) \\Biggr)\n",
    "$$\n",
    "\n",
    "where $\\phi(h) = \\tanh(\\beta h)$, and we use $\\beta = 4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 0.1 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a method that generates binary balanced random patterns; and a method that computes the next state $S(t + 1)$ of the network, given the current state $S(t) = (S_1(t), . . . , S_N(t))$ and a set of patterns $P^1, ..., P^M$ according to eqs.(1)-(2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from neurodynex3.hopfield_network import network, pattern_tools, plot_tools\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "N = 100  # Number of neurons\n",
    "M = 5    # Number of patterns\n",
    "beta = 4 # The temperature\n",
    "\n",
    "# Generate a random pattern:\n",
    "def generate_random_pattern(N):\n",
    "    P = np.random.binomial(1, 0.5, N)\n",
    "    P = P * 2 - 1  # map {0, 1} to {-1 +1}\n",
    "    return P\n",
    "\n",
    "# Generate M random patterns:\n",
    "def generate_pattern_set(M, N):\n",
    "    P_set = np.zeros((M, N))\n",
    "    for mu in range(M):\n",
    "        P_set[mu] = generate_random_pattern(N)\n",
    "    return P_set\n",
    "\n",
    "# The phi function:\n",
    "def phi(beta, h):\n",
    "    return np.tanh(beta*h)\n",
    "\n",
    "# Calculate the S(t+1) values:\n",
    "def next_state(S_old, P_set):\n",
    "    S_new = np.zeros(N)\n",
    "    W = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            W[i, j] = np.sum(P_set[:, i] * P_set[:, j]) / N\n",
    "    for j in range(N):\n",
    "        S_new[j] = phi(beta, np.sum(W[:, j] * S_old[j]))\n",
    "    return S_new\n",
    "\n",
    "# Iterate n_step times:\n",
    "def S_iterate(S_old, P_set, n_step):\n",
    "    for i in range(n_step):\n",
    "        S_old = next_state(S_old, P_set)\n",
    "    return S_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 0.2 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a network with $N = 100$ neurons and $M = 5$ patterns, set the initial state close to the first pattern $P^1$.\n",
    "\n",
    "To do this, randomly flip a given percentage c = 5% of neurons in the pattern.\n",
    "\n",
    "Let the network evolve for 10-20 time steps until the network dynamics relax to a stable state.\n",
    "\n",
    "Check the overlaps of the final state with all the patterns. Did the network correctly retrieve the first pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap between pattern 0 and the final state: 0.30\n",
      "Overlap between pattern 1 and the final state: -0.04\n",
      "Overlap between pattern 2 and the final state: -0.06\n",
      "Overlap between pattern 3 and the final state: -0.13\n",
      "Overlap between pattern 4 and the final state: 0.03\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from neurodynex3.hopfield_network import network, pattern_tools, plot_tools\n",
    "\n",
    "n_step = 20\n",
    "\n",
    "# Pattern flipper:\n",
    "def random_flip(P, c):\n",
    "    P_new = np.copy(P)\n",
    "    for i in range(int(c*N)):\n",
    "        idx = np.random.randint(0, N)\n",
    "        P_new[idx] = -P[idx]\n",
    "    return P_new\n",
    "\n",
    "P_set = generate_pattern_set(M, N)\n",
    "S0 = random_flip(P_set[0], 0.05)\n",
    "S_final = S_iterate(S0, P_set, n_step)\n",
    "\n",
    "# Compute Overlap:\n",
    "def overlap(P1, P2):\n",
    "    return np.sum(P1*P2) / N\n",
    "\n",
    "# Compute the overlap between the patterns and the final state:\n",
    "overlap_list = np.zeros(M)\n",
    "for mu in range(M):\n",
    "    overlap_list[mu] = overlap(S_final, P_set[mu])\n",
    "    print(\"Overlap between pattern %d and the final state: %.2f\" % (mu, overlap_list[mu]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
